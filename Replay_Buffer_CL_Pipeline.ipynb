{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Continual Learning Pipeline implementation on MNIST Dataset"
      ],
      "metadata": {
        "id": "AyF9rCx99S11"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Continual learning** (also known as **lifelong learning**) refers to the ability of a machine learning model or system to continuously learn and adapt to new information or tasks over time, without forgetting previously learned knowledge. Unlike traditional machine learning, which typically trains on a fixed dataset and then remains static, continual learning allows models to evolve and improve as they are exposed to new data.\n",
        "\n",
        "Key characteristics of continual learning include:\n",
        "\n",
        "1. **Learning from New Data**: The model is capable of incorporating new information or tasks while maintaining performance on earlier tasks.\n",
        "  \n",
        "2. **Avoiding Catastrophic Forgetting**: A major challenge in continual learning is ensuring that the model doesn't forget previously learned tasks when learning new ones.\n",
        "\n",
        "3. **Adaptation to Changing Environments**: The model can adjust to changes in data distribution or new tasks that weren't initially part of its training.\n",
        "\n",
        "4. **Efficiency**: The system should be able to learn and update efficiently, often with limited computational resources and without requiring retraining from scratch.\n",
        "\n",
        "In practice, continual learning is important in areas such as robotics, autonomous systems, and real-time data analysis, where new experiences or information continually emerge."
      ],
      "metadata": {
        "id": "0jKnguRl9htB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation using Avalanche\n",
        "\n",
        "**Avalanche** is a framework designed to support **continual learning** in machine learning. It provides tools and libraries for building, testing, and evaluating continual learning models, helping researchers and practitioners develop algorithms that can learn over time without forgetting previously acquired knowledge.\n",
        "\n",
        "### Key Features of Avalanche:\n",
        "1. **Task-Incremental Learning**: It supports various types of continual learning paradigms, such as task-incremental learning, where the model encounters new tasks over time and needs to retain knowledge from previous tasks.\n",
        "  \n",
        "2. **Support for Different Scenarios**: Avalanche provides flexibility in handling different scenarios in continual learning, including:\n",
        "   - **Class-incremental learning**: Where classes are introduced one by one.\n",
        "   - **Domain-incremental learning**: Where the domain or distribution changes over time, such as in changing environments or evolving data distributions.\n",
        "\n",
        "3. **Benchmarking**: The framework offers tools to evaluate models on several well-established continual learning benchmarks, allowing researchers to test the effectiveness of their models and compare them against others in the field.\n",
        "\n",
        "4. **Memory Management**: Since continual learning often involves a challenge of avoiding **catastrophic forgetting**, Avalanche provides tools to implement memory mechanisms, such as replay buffers, to help retain useful information from past tasks.\n",
        "\n",
        "5. **Flexible Integration**: Avalanche is compatible with popular deep learning libraries like PyTorch, making it easy to integrate into existing workflows.\n",
        "\n",
        "6. **Metrics and Evaluation**: The framework offers a range of evaluation metrics, such as accuracy, forgetting, and others that are specifically useful in continual learning scenarios.\n",
        "\n",
        "### Why Avalanche is Important:\n",
        "Continual learning poses several challenges, notably **catastrophic forgetting**, where models forget previously learned tasks or knowledge when exposed to new tasks. Avalanche aids in developing and testing solutions to this problem by providing a structured environment to experiment with strategies such as:\n",
        "- **Replay methods**, where previously encountered data or tasks are replayed to avoid forgetting.\n",
        "- **Regularization techniques**, which help preserve older knowledge while allowing the model to adapt to new tasks.\n",
        "\n",
        "By using Avalanche, researchers can advance our understanding of how models can learn continuously and effectively over time, making it a valuable tool in the field of **lifelong learning**."
      ],
      "metadata": {
        "id": "XceTytHT9leE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "fDHD9sub90th"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hODnYlUWRmy-",
        "outputId": "577ee06a-56d2-4fcf-f8ac-5ce89e66cdf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ContinualAI/avalanche.git\n",
            "  Cloning https://github.com/ContinualAI/avalanche.git to /tmp/pip-req-build-kbpwvza1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/ContinualAI/avalanche.git /tmp/pip-req-build-kbpwvza1\n",
            "  Resolved https://github.com/ContinualAI/avalanche.git to commit 625e46d9203878ed51457f6d7cd8d4e9fb05d093\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0a0) (4.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0a0) (5.9.5)\n",
            "Collecting gputil (from avalanche-lib==0.6.0a0)\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0a0) (1.5.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0a0) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0a0) (1.26.4)\n",
            "Collecting pytorchcv (from avalanche-lib==0.6.0a0)\n",
            "  Downloading pytorchcv-0.0.73-py2.py3-none-any.whl.metadata (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.2/134.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0a0) (0.18.7)\n",
            "Requirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0a0) (2.17.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0a0) (4.66.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0a0) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0a0) (0.20.1+cu121)\n",
            "Collecting torchmetrics (from avalanche-lib==0.6.0a0)\n",
            "  Downloading torchmetrics-1.6.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0a0) (5.2.0)\n",
            "Collecting qpsolvers[open_source_solvers] (from avalanche-lib==0.6.0a0)\n",
            "  Downloading qpsolvers-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting dill (from avalanche-lib==0.6.0a0)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from avalanche-lib==0.6.0a0) (24.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0a0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0a0) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0a0) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0a0) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0a0) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0a0) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0a0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6.0a0) (3.1.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->avalanche-lib==0.6.0a0) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->avalanche-lib==0.6.0a0) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->avalanche-lib==0.6.0a0) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.6.0a0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.6.0a0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.6.0a0) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.6.0a0) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.6.0a0) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.6.0a0) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->avalanche-lib==0.6.0a0) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->avalanche-lib==0.6.0a0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->avalanche-lib==0.6.0a0) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.6.0a0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.6.0a0) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.6.0a0) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->avalanche-lib==0.6.0a0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->avalanche-lib==0.6.0a0) (1.3.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics->avalanche-lib==0.6.0a0)\n",
            "  Downloading lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0a0) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0a0) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0a0) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0a0) (4.3.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0a0) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0a0) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->avalanche-lib==0.6.0a0) (1.3.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.6.0a0) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6.0a0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6.0a0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6.0a0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6.0a0) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=1.15->avalanche-lib==0.6.0a0) (3.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->avalanche-lib==0.6.0a0) (2.6)\n",
            "Collecting quadprog>=0.1.11 (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0)\n",
            "  Downloading quadprog-0.1.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: cvxopt>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0) (1.3.2)\n",
            "Requirement already satisfied: clarabel>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0) (0.9.0)\n",
            "Collecting qpax>=0.0.9 (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0)\n",
            "  Downloading qpax-0.0.9-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting daqp>=0.5.1 (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0)\n",
            "  Downloading daqp-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0) (0.6.7.post3)\n",
            "Collecting proxsuite>=0.2.9 (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0)\n",
            "  Downloading proxsuite-0.6.7-0-cp310-cp310-manylinux_2_17_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: scs>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0) (3.2.7)\n",
            "Collecting qpalm>=1.2.1 (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0)\n",
            "  Downloading qpalm-1.2.5-cp310-cp310-manylinux_2_17_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: ecos>=2.0.8 in /usr/local/lib/python3.10/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0) (2.0.14)\n",
            "Collecting piqp>=0.2.2 (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0)\n",
            "  Downloading piqp-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting highspy>=1.1.2.dev3 (from qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0)\n",
            "  Downloading highspy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6.0a0) (1.7.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.6.0a0) (5.0.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.6.2->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0) (0.1.7.post4)\n",
            "Collecting cmeel (from proxsuite>=0.2.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0)\n",
            "  Downloading cmeel-0.53.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: jax>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from qpax>=0.0.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0) (0.4.33)\n",
            "Requirement already satisfied: jaxlib>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from qpax>=0.0.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0) (0.4.33)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.0->qpax>=0.0.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.0->qpax>=0.0.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0) (3.4.0)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from cmeel->proxsuite>=0.2.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6.0a0) (2.2.1)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytorchcv-0.0.73-py2.py3-none-any.whl (585 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m585.2/585.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchmetrics-1.6.0-py3-none-any.whl (926 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.4/926.4 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.11.9-py3-none-any.whl (28 kB)\n",
            "Downloading qpsolvers-4.4.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading daqp-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (558 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.6/558.6 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading highspy-1.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading piqp-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (979 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m979.8/979.8 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading proxsuite-0.6.7-0-cp310-cp310-manylinux_2_17_x86_64.whl (2.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qpalm-1.2.5-cp310-cp310-manylinux_2_17_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qpax-0.0.9-py3-none-any.whl (11 kB)\n",
            "Downloading quadprog-0.1.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (505 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.9/505.9 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cmeel-0.53.3-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: avalanche-lib, gputil\n",
            "  Building wheel for avalanche-lib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avalanche-lib: filename=avalanche_lib-0.6.0a0-py3-none-any.whl size=988620 sha256=5a4bcd2e0e2864e0afcc7f4342c1673a13592b68b70b96c10caeb6c7c5bc795f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ndvjad_r/wheels/b9/ef/1f/e002050b2856b248d8a06d1e0c30a722d6d8a73a22d0b3e9c2\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=e80c886896a31bc0c03625e67e0bca05936456bb8b4f857a6ccd928505dc4cdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built avalanche-lib gputil\n",
            "Installing collected packages: gputil, daqp, quadprog, piqp, lightning-utilities, highspy, dill, cmeel, qpsolvers, qpalm, proxsuite, torchmetrics, qpax, pytorchcv, avalanche-lib\n",
            "Successfully installed avalanche-lib-0.6.0a0 cmeel-0.53.3 daqp-0.6.0 dill-0.3.9 gputil-1.4.0 highspy-1.8.1 lightning-utilities-0.11.9 piqp-0.4.2 proxsuite-0.6.7 pytorchcv-0.0.73 qpalm-1.2.5 qpax-0.0.9 qpsolvers-4.4.0 quadprog-0.1.13 torchmetrics-1.6.0\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/ContinualAI/avalanche.git"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation"
      ],
      "metadata": {
        "id": "SlQ0gFmo-NEO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "kVWY3eRm-PyL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtZiURGNRsVd"
      },
      "outputs": [],
      "source": [
        "from torch.optim import SGD\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from avalanche.benchmarks.classic import SplitMNIST\n",
        "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics, \\\n",
        "    loss_metrics, timing_metrics, cpu_usage_metrics, confusion_matrix_metrics, disk_usage_metrics\n",
        "from avalanche.models import SimpleMLP\n",
        "from avalanche.logging import InteractiveLogger, TextLogger, TensorboardLogger\n",
        "from avalanche.training.plugins import EvaluationPlugin\n",
        "from avalanche.training.supervised import Naive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Benchmark"
      ],
      "metadata": {
        "id": "VGShCTgc-p4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZDz-VseSo8d",
        "outputId": "4b8a3159-39ff-462f-9242-aee0f85c94a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 35.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.avalanche/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.36MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.avalanche/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.avalanche/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.06MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.avalanche/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# here it is creating benchmark using 5 tasks as [0,1],[2,3],[4,5],[6,7],[8,9]\n",
        "\n",
        "scenario = SplitMNIST(n_experiences=5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create The Model"
      ],
      "metadata": {
        "id": "Ns81d5gX_PD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleMLP(num_classes=scenario.n_classes)\n"
      ],
      "metadata": {
        "id": "ayiF7Fh0-r_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Evaluation Plugin and Loggers"
      ],
      "metadata": {
        "id": "4iUlQKlx_b8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loggers to record and visualize metrics\n",
        "tb_logger = TensorboardLogger()\n",
        "# for storing logs in text file\n",
        "text_logger = TextLogger(open('log.txt', 'a'))\n",
        "# printing Logs\n",
        "interactive_logger = InteractiveLogger()\n",
        "\n",
        "# Evaluation plugin to manage and log metrics\n",
        "eval_plugin = EvaluationPlugin(\n",
        "    accuracy_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "    loss_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "    timing_metrics(epoch=True, epoch_running=True),\n",
        "    forgetting_metrics(experience=True, stream=True),\n",
        "    cpu_usage_metrics(experience=True),\n",
        "    confusion_matrix_metrics(num_classes=scenario.n_classes, save_image=False, stream=True),\n",
        "    disk_usage_metrics(minibatch=True, epoch=True, experience=True, stream=True),\n",
        "    loggers=[interactive_logger, text_logger, tb_logger]\n",
        ")\n"
      ],
      "metadata": {
        "id": "E9xYIBKQ_SEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Naive Strategy\n",
        "**Naive**: This is a basic strategy for training a model on each task. In continual learning, the Naive strategy doesn't use any techniques like replay or regularization to prevent forgetting. It just trains the model on the current task.\n",
        "\n",
        "**SGD**: Stochastic Gradient Descent optimizer with a learning rate of 0.001 and momentum of 0.9.\n",
        "\n",
        "CrossEntropyLoss: Loss function used for classification tasks.\n",
        "\n",
        "train_mb_size=500: The mini-batch size during training (500 samples).\n",
        "\n",
        "train_epochs=1: The number of epochs (1 epoch per experience).\n",
        "\n",
        "eval_mb_size=100: The mini-batch size during evaluation.\n",
        "\n",
        "evaluator=eval_plugin: The evaluation plugin to track and log metrics during training."
      ],
      "metadata": {
        "id": "23u1e-8V_swk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cl_strategy = Naive(\n",
        "    model, SGD(model.parameters(), lr=0.001, momentum=0.9),\n",
        "    CrossEntropyLoss(), train_mb_size=500, train_epochs=1, eval_mb_size=100,\n",
        "    evaluator=eval_plugin)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-cx7oFC_qrV",
        "outputId": "a96bdcb7-04fd-40bc-8b25-bc1aea11dd02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/avalanche/training/templates/base.py:468: PositionalArgumentsDeprecatedWarning: Avalanche is transitioning to strategy constructors that accept named (keyword) arguments only. This is done to ensure that there is no confusion regarding the meaning of each argument (strategies can have many arguments). Your are passing 3 positional arguments to the Naive.__init__ method. Consider passing them as names arguments. The ability to pass positional arguments will be removed in the future.\n",
            "  warnings.warn(error_str, category=PositionalArgumentsDeprecatedWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop"
      ],
      "metadata": {
        "id": "kqbSoL9y__nR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Start training loop\n",
        "print('Starting experiment...')\n",
        "results = []\n",
        "for experience in scenario.train_stream:\n",
        "    print(\"Start of experience: \", experience.current_experience)\n",
        "    print(\"Current Classes: \", experience.classes_in_this_experience)\n",
        "\n",
        "    # Train on the current experience\n",
        "    res = cl_strategy.train(experience)\n",
        "    print('Training completed')\n",
        "\n",
        "    # Evaluate on the entire test set\n",
        "    print('Computing accuracy on the whole test set')\n",
        "    results.append(cl_strategy.eval(scenario.test_stream))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TNFIeq2_7h9",
        "outputId": "82c7f0c1-b510-476c-d2c5-785c13927761"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting experiment...\n",
            "Start of experience:  0\n",
            "Current Classes:  [0, 1]\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 26/26 [00:03<00:00,  8.36it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55612.8779\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55612.8779\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 0.9452\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 0.1016\n",
            "\tRunningTime_Epoch/train_phase/train_stream/Task000 = 0.0113\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 3.1028\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8131\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 1.0000\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 31.17it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 86.5873\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55612.8779\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0784\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9967\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 29.88it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 87.0584\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55612.8779\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 4.0676\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 29.90it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 87.1216\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55612.8779\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.9280\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 31.09it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 88.7428\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55612.8779\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 4.8483\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 19/19 [00:00<00:00, 29.05it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 87.4953\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55612.8779\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.7897\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[ 974,    6,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [   1, 1134,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 470,  562,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 396,  614,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 537,  445,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 594,  298,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 664,  294,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 465,  563,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 307,  667,    0,    0,    0,    0,    0,    0,    0,    0],\n",
            "        [ 478,  531,    0,    0,    0,    0,    0,    0,    0,    0]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55612.8779\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.6880\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.0000\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2108\n",
            "Start of experience:  1\n",
            "Current Classes:  [4, 7]\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 25/25 [00:03<00:00,  6.38it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55628.8779\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55628.8779\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 1.8430\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 0.4168\n",
            "\tRunningTime_Epoch/train_phase/train_stream/Task000 = 0.0077\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 3.9102\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4481\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9065\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 24.37it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 86.1885\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55628.8779\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.3764\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.0647\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6203\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 31.15it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 86.8138\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55628.8779\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3583\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9592\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 29.87it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 88.2923\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55628.8779\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 4.7279\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 29.12it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 86.2909\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55628.8779\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 5.1510\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 19/19 [00:00<00:00, 29.20it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 89.0074\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55628.8779\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.7051\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[488,   0,   0,   0, 393,   0,   0,  99,   0,   0],\n",
            "        [  0, 824,   0,   0, 102,   0,   0, 209,   0,   0],\n",
            "        [  4,  31,   0,   0, 647,   0,   0, 350,   0,   0],\n",
            "        [  2,   0,   0,   0, 336,   0,   0, 672,   0,   0],\n",
            "        [  0,   0,   0,   0, 953,   0,   0,  29,   0,   0],\n",
            "        [  1,   4,   0,   0, 515,   0,   0, 372,   0,   0],\n",
            "        [  2,   3,   0,   0, 936,   0,   0,  17,   0,   0],\n",
            "        [  0,   1,   0,   0,  52,   0,   0, 975,   0,   0],\n",
            "        [  0,   1,   0,   0, 674,   0,   0, 299,   0,   0],\n",
            "        [  0,   0,   0,   0, 692,   0,   0, 317,   0,   0]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55628.8779\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 3.1545\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.3764\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3240\n",
            "Start of experience:  2\n",
            "Current Classes:  [2, 3]\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 25/25 [00:03<00:00,  7.72it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55644.8779\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55644.8779\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2696\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 0.6217\n",
            "\tRunningTime_Epoch/train_phase/train_stream/Task000 = 0.0219\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 3.2332\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3892\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8539\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 30.11it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 88.6569\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55644.8779\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.8539\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.8308\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.1428\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 30.57it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 87.4372\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55644.8779\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.6403\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 1.4721\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.3189\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 28.48it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 88.5601\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55652.8350\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 0.4875\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9270\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 28.07it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 86.4826\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55652.8350\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 4.4840\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 19/19 [00:00<00:00, 30.21it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 90.0108\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55652.8350\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 4.1222\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[ 45,   0, 377, 558,   0,   0,   0,   0,   0,   0],\n",
            "        [  0, 257, 272, 606,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0, 930, 100,   1,   0,   0,   1,   0,   0],\n",
            "        [  0,   0,  45, 963,   0,   0,   0,   2,   0,   0],\n",
            "        [  0,   0, 675, 207, 100,   0,   0,   0,   0,   0],\n",
            "        [  0,   0, 177, 710,   3,   0,   0,   2,   0,   0],\n",
            "        [  0,   0, 842, 115,   1,   0,   0,   0,   0,   0],\n",
            "        [  0,   0, 273, 211,   3,   0,   0, 541,   0,   0],\n",
            "        [  0,   0, 366, 608,   0,   0,   0,   0,   0,   0],\n",
            "        [  0,   0, 527, 478,   2,   0,   0,   2,   0,   0]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55652.8350\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 2.4344\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.7471\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2836\n",
            "Start of experience:  3\n",
            "Current Classes:  [8, 9]\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 24/24 [00:04<00:00,  5.87it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55668.8350\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55668.8350\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5082\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 0.9598\n",
            "\tRunningTime_Epoch/train_phase/train_stream/Task000 = 0.0132\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 4.0842\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3009\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.9200\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 31.25it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 88.0637\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55668.8350\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.7333\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.8509\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.2634\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 28.79it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 86.6582\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55668.8350\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.9498\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.1836\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0095\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 28.69it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 87.5253\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55668.8350\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp002 = 0.7331\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 1.5617\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.1939\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 28.64it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 87.0459\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55668.8350\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 0.8300\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9314\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 19/19 [00:00<00:00, 28.60it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 86.4845\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55668.8350\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 3.5218\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[241,   0, 103,  18,   0,   0,   0,   0, 556,  62],\n",
            "        [  0, 316,   0,   0,   0,   0,   0,   0, 815,   4],\n",
            "        [  0,   0, 322,   1,   0,   0,   0,   1, 616,  92],\n",
            "        [  0,   0,   2,  74,   0,   0,   0,   0, 906,  28],\n",
            "        [  0,   0,   3,   0,   0,   0,   0,   0,  46, 933],\n",
            "        [  0,   0,   4,   2,   0,   0,   0,   0, 736, 150],\n",
            "        [  0,   0,  89,   0,   0,   0,   0,   0, 575, 294],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,  19,  84, 925],\n",
            "        [  0,   0,   0,   0,   0,   0,   0,   0, 894,  80],\n",
            "        [  0,   0,   1,   0,   0,   0,   0,   0,  55, 953]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55668.8350\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.9654\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.8054\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.2819\n",
            "Start of experience:  4\n",
            "Current Classes:  [5, 6]\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 23/23 [00:02<00:00,  8.47it/s]\n",
            "Epoch 0 ended.\n",
            "\tDiskUsage_Epoch/train_phase/train_stream/Task000 = 55684.8350\n",
            "\tDiskUsage_MB/train_phase/train_stream/Task000 = 55684.8350\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4495\n",
            "\tLoss_MB/train_phase/train_stream/Task000 = 1.2275\n",
            "\tRunningTime_Epoch/train_phase/train_stream/Task000 = 0.0075\n",
            "\tTime_Epoch/train_phase/train_stream/Task000 = 2.7119\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1938\n",
            "\tTop1_Acc_MB/train_phase/train_stream/Task000 = 0.8437\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 28.16it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 87.8461\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 55684.8350\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.6662\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 2.0047\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.3305\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 30.27it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 89.8196\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp001 = 55684.8350\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp001 = 0.9557\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 2.3961\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0035\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 27.50it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 87.1478\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp002 = 55684.8350\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp002 = 0.9172\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 2.2490\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0098\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 27.61it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 87.3955\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp003 = 55684.8350\n",
            "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp003 = 0.4377\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 1.4396\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.4937\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 19/19 [00:00<00:00, 20.88it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 79.9235\n",
            "\tDiskUsage_Exp/eval_phase/test_stream/Task000/Exp004 = 55692.8330\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp004 = 1.0937\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.8768\n",
            "-- >> End of eval phase << --\n",
            "\tConfusionMatrix_Stream/eval_phase/test_stream = \n",
            "tensor([[139,   0,   7,   2,   0, 395, 421,   0,   8,   8],\n",
            "        [  0, 560,   0,   0,   0, 105, 110,   0, 334,  26],\n",
            "        [  1,   0,  11,   0,   0,  41, 825,   0, 127,  27],\n",
            "        [  0,   0,   0,   9,   0, 825,  73,   0,  64,  39],\n",
            "        [  0,   0,   0,   0,   0,   1, 263,   0,   2, 716],\n",
            "        [  0,   1,   0,   1,   0, 684, 144,   0,  16,  46],\n",
            "        [  0,   1,   1,   0,   0,  13, 938,   0,   2,   3],\n",
            "        [  0,   0,   0,   0,   0,   6,  57,   7,  15, 943],\n",
            "        [  0,   0,   0,   0,   0, 466, 393,   0,  67,  48],\n",
            "        [  0,   0,   0,   0,   0,  35,  60,   0,   2, 912]])\n",
            "\tDiskUsage_Stream/eval_phase/test_stream/Task000 = 55692.8330\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 1.8527\n",
            "\tStreamForgetting/eval_phase/test_stream = 0.7442\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Explanation\n",
        "As we have seen above we used simple Naive approach and the model accuracy decreases on previoulsy learned classes so we are going to use some CL approaches to stop Forgetting"
      ],
      "metadata": {
        "id": "F0tud_1iKVb-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GroupBalancedDataLoader**\n",
        "\n",
        "GroupBalancedDataLoader takes a sequence of datasets and iterates over them by providing balanced mini-batches, where the number of samples is split equally among groups. Internally, it instantiate a DataLoader for each separate group."
      ],
      "metadata": {
        "id": "UxeGHye_SXrX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from avalanche.benchmarks import SplitMNIST\n",
        "from avalanche.benchmarks.utils.data_loader import GroupBalancedDataLoader\n",
        "benchmark = SplitMNIST(5, return_task_id=True)\n",
        "\n",
        "dl = GroupBalancedDataLoader([exp.dataset for exp in benchmark.train_stream], batch_size=5)\n",
        "for x, y, t in dl:\n",
        "    print(t.tolist())\n",
        "    break"
      ],
      "metadata": {
        "id": "7jMTM5EVAA_K",
        "outputId": "8d1c67da-8a65-4fbc-f5a6-c599a03fd5d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ReservoirSamplingBuffer**\n",
        "\n",
        "Memory buffers store data up to a maximum capacity, and they implement policies to select which data to store and which the to remove when the buffer is full."
      ],
      "metadata": {
        "id": "Yg5UQZiNSyHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from avalanche.training.storage_policy import ReservoirSamplingBuffer\n",
        "from types import SimpleNamespace\n",
        "\n",
        "benchmark = SplitMNIST(5, return_task_id=False)\n",
        "storage_p = ReservoirSamplingBuffer(max_size=30)\n",
        "\n",
        "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")"
      ],
      "metadata": {
        "id": "2aMlnfLnRDoz",
        "outputId": "60c4225f-a021-4b5b-a6a6-1d9b032a0287",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max buffer size: 30, current size: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " We use a SimpleNamespace because we want to use the buffer standalone, without instantiating an Avalanche strategy. Reservoir sampling requires only the experience from the strategy's state."
      ],
      "metadata": {
        "id": "NKgGiCUvS9Q4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    strategy_state = SimpleNamespace(experience=benchmark.train_stream[i])\n",
        "    storage_p.update(strategy_state)\n",
        "    print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
        "    print(f\"class targets: {storage_p.buffer.targets.uniques}\\n\")"
      ],
      "metadata": {
        "id": "52YmHMGqRJfg",
        "outputId": "1e5d5847-7820-48a0-8eac-1fa3397bb81f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max buffer size: 30, current size: 30\n",
            "class targets: {4, 7}\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: {1, 4, 6, 7}\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: {1, 3, 4, 6, 7, 9}\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: {1, 3, 4, 5, 6, 7, 8, 9}\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-b534ddf892b6>:3: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  storage_p.update(strategy_state)\n",
            "<ipython-input-11-b534ddf892b6>:3: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  storage_p.update(strategy_state)\n",
            "<ipython-input-11-b534ddf892b6>:3: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  storage_p.update(strategy_state)\n",
            "<ipython-input-11-b534ddf892b6>:3: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  storage_p.update(strategy_state)\n",
            "<ipython-input-11-b534ddf892b6>:3: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  storage_p.update(strategy_state)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ParametricBuffer**\n",
        "\n",
        "ParametricBuffer is a buffer split into several groups according to the groupby parameters (None, 'class', 'task', 'experience'), and according to an optional ExemplarsSelectionStrategy (random selection is the default choice)."
      ],
      "metadata": {
        "id": "HQPAbguQTI8V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from avalanche.training.storage_policy import ParametricBuffer, RandomExemplarsSelectionStrategy\n",
        "storage_p = ParametricBuffer(\n",
        "    max_size=30,\n",
        "    groupby='class',\n",
        "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
        ")\n",
        "\n",
        "print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
        "for i in range(5):\n",
        "    strategy_state = SimpleNamespace(experience=benchmark.train_stream[i])\n",
        "    storage_p.update(strategy_state)\n",
        "    print(f\"Max buffer size: {storage_p.max_size}, current size: {len(storage_p.buffer)}\")\n",
        "    print(f\"class targets: {storage_p.buffer.targets.uniques}\\n\")"
      ],
      "metadata": {
        "id": "QHundMYIRVvo",
        "outputId": "afb2b4b7-4a8c-4f32-e1a6-30812bc58f9f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max buffer size: 30, current size: 0\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: {4, 7}\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: {1, 4, 6, 7}\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: {1, 3, 4, 6, 7, 9}\n",
            "\n",
            "Max buffer size: 30, current size: 30\n",
            "class targets: {1, 3, 4, 5, 6, 7, 8, 9}\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-6a4a72fdc594>:11: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  storage_p.update(strategy_state)\n",
            "<ipython-input-12-6a4a72fdc594>:11: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  storage_p.update(strategy_state)\n",
            "<ipython-input-12-6a4a72fdc594>:11: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  storage_p.update(strategy_state)\n",
            "<ipython-input-12-6a4a72fdc594>:11: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  storage_p.update(strategy_state)\n",
            "<ipython-input-12-6a4a72fdc594>:11: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  storage_p.update(strategy_state)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max buffer size: 30, current size: 30\n",
            "class targets: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The advantage of using grouping buffers is that you get a balanced rehearsal buffer. You can even access the groups separately with the buffer_groups attribute. Combined with balanced dataloaders, you can ensure that the mini-batches stay balanced during training."
      ],
      "metadata": {
        "id": "iIz6fh_TTUhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in storage_p.buffer_groups.items():\n",
        "    print(f\"(group {k}) -> size {len(v.buffer)}\")"
      ],
      "metadata": {
        "id": "1hozlQ6mRkiN",
        "outputId": "7b85dc6e-9e7a-4b18-e0ff-a1ac3a872abe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(group 4) -> size 3\n",
            "(group 7) -> size 3\n",
            "(group 1) -> size 3\n",
            "(group 6) -> size 3\n",
            "(group 9) -> size 3\n",
            "(group 3) -> size 3\n",
            "(group 8) -> size 3\n",
            "(group 5) -> size 3\n",
            "(group 0) -> size 3\n",
            "(group 2) -> size 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datas = [v.buffer for v in storage_p.buffer_groups.values()]\n",
        "dl = GroupBalancedDataLoader(datas)\n",
        "\n",
        "for x, y, t in dl:\n",
        "    print(y.tolist())\n",
        "    break"
      ],
      "metadata": {
        "id": "8ShstInORpV4",
        "outputId": "69567948-631d-47c3-a673-6cb13d40edb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4, 4, 4, 7, 7, 7, 1, 1, 1, 6, 6, 6, 9, 9, 9, 3, 3, 3, 8, 8, 8, 5, 5, 5, 0, 0, 0, 2, 2, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Replay Plugins**\n",
        "\n",
        "Avalanche's strategy plugins can be used to update the rehearsal buffer and set the dataloader. This allows to easily implement replay strategies"
      ],
      "metadata": {
        "id": "tYWdJHtiTYKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from avalanche.benchmarks.utils.data_loader import ReplayDataLoader\n",
        "from avalanche.training.plugins import SupervisedPlugin\n",
        "\n",
        "class CustomReplay(SupervisedPlugin):\n",
        "    def __init__(self, storage_policy):\n",
        "        super().__init__()\n",
        "        self.storage_policy = storage_policy\n",
        "\n",
        "    def before_training_exp(self, strategy,\n",
        "                            num_workers: int = 0, shuffle: bool = True,\n",
        "                            **kwargs):\n",
        "        \"\"\" Here we set the dataloader. \"\"\"\n",
        "        if len(self.storage_policy.buffer) == 0:\n",
        "            # first experience. We don't use the buffer, no need to change\n",
        "            # the dataloader.\n",
        "            return\n",
        "\n",
        "        # replay dataloader samples mini-batches from the memory and current\n",
        "        # data separately and combines them together.\n",
        "        print(\"Override the dataloader.\")\n",
        "        strategy.dataloader = ReplayDataLoader(\n",
        "            strategy.adapted_dataset,\n",
        "            self.storage_policy.buffer,\n",
        "            oversample_small_tasks=True,\n",
        "            num_workers=num_workers,\n",
        "            batch_size=strategy.train_mb_size,\n",
        "            shuffle=shuffle)\n",
        "\n",
        "    def after_training_exp(self, strategy: \"BaseStrategy\", **kwargs):\n",
        "        \"\"\" We update the buffer after the experience.\n",
        "            You can use a different callback to update the buffer in a different place\n",
        "        \"\"\"\n",
        "        print(\"Buffer update.\")\n",
        "        self.storage_policy.update(strategy, **kwargs)"
      ],
      "metadata": {
        "id": "aBBUb97NRrIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the plugin to train our continual model."
      ],
      "metadata": {
        "id": "_1vxqbX8T2zm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "from avalanche.training import Naive\n",
        "from avalanche.evaluation.metrics import accuracy_metrics\n",
        "from avalanche.training.plugins import EvaluationPlugin\n",
        "from avalanche.logging import InteractiveLogger\n",
        "from avalanche.models import SimpleMLP\n",
        "import torch\n",
        "\n",
        "scenario = SplitMNIST(5)\n",
        "model = SimpleMLP(num_classes=scenario.n_classes)\n",
        "storage_p = ParametricBuffer(\n",
        "    max_size=500,\n",
        "    groupby='class',\n",
        "    selection_strategy=RandomExemplarsSelectionStrategy()\n",
        ")\n",
        "\n",
        "# choose some metrics and evaluation method\n",
        "interactive_logger = InteractiveLogger()\n",
        "\n",
        "eval_plugin = EvaluationPlugin(\n",
        "    accuracy_metrics(experience=True, stream=True),\n",
        "    loggers=[interactive_logger])\n",
        "\n",
        "# CREATE THE STRATEGY INSTANCE (NAIVE)\n",
        "cl_strategy = Naive(model, torch.optim.Adam(model.parameters(), lr=0.001),\n",
        "                    CrossEntropyLoss(),\n",
        "                    train_mb_size=100, train_epochs=1, eval_mb_size=100,\n",
        "                    plugins=[CustomReplay(storage_p)],\n",
        "                    evaluator=eval_plugin\n",
        "                    )\n",
        "\n",
        "# TRAINING LOOP\n",
        "print('Starting experiment...')\n",
        "results = []\n",
        "for experience in scenario.train_stream:\n",
        "    print(\"Start of experience \", experience.current_experience)\n",
        "    cl_strategy.train(experience)\n",
        "    print('Training completed')\n",
        "\n",
        "    print('Computing accuracy on the whole test set')\n",
        "    results.append(cl_strategy.eval(scenario.test_stream))"
      ],
      "metadata": {
        "id": "i4UerUXtRv0C",
        "outputId": "09ed3a63-b0b4-4ad5-aeec-2c54d317c257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/avalanche/training/templates/base.py:468: PositionalArgumentsDeprecatedWarning: Avalanche is transitioning to strategy constructors that accept named (keyword) arguments only. This is done to ensure that there is no confusion regarding the meaning of each argument (strategies can have many arguments). Your are passing 3 positional arguments to the Naive.__init__ method. Consider passing them as names arguments. The ability to pass positional arguments will be removed in the future.\n",
            "  warnings.warn(error_str, category=PositionalArgumentsDeprecatedWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting experiment...\n",
            "Start of experience  0\n",
            "-- >> Start of training phase << --\n",
            "100%|██████████| 122/122 [00:04<00:00, 27.69it/s]\n",
            "Epoch 0 ended.\n",
            "Buffer update.\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-04bf1c5bdbc6>:34: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  self.storage_policy.update(strategy, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 42.89it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9855\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 35.22it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 41.86it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 35.54it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 37.71it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.1973\n",
            "Start of experience  1\n",
            "-- >> Start of training phase << --\n",
            "Override the dataloader.\n",
            "100%|██████████| 116/116 [00:04<00:00, 25.29it/s]\n",
            "Epoch 0 ended.\n",
            "Buffer update.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-04bf1c5bdbc6>:34: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  self.storage_policy.update(strategy, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 27.43it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9276\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 31.33it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.9506\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 28.38it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 25.68it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 26.49it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.3665\n",
            "Start of experience  2\n",
            "-- >> Start of training phase << --\n",
            "Override the dataloader.\n",
            "100%|██████████| 118/118 [00:04<00:00, 25.27it/s]\n",
            "Epoch 0 ended.\n",
            "Buffer update.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-04bf1c5bdbc6>:34: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  self.storage_policy.update(strategy, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 42.51it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8631\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 35.44it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8901\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 40.99it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.9782\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 35.73it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 36.36it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.5391\n",
            "Start of experience  3\n",
            "-- >> Start of training phase << --\n",
            "Override the dataloader.\n",
            "100%|██████████| 119/119 [00:05<00:00, 21.55it/s]\n",
            "Epoch 0 ended.\n",
            "Buffer update.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-04bf1c5bdbc6>:34: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  self.storage_policy.update(strategy, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 26.72it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8966\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 38.80it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8728\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 38.18it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.8928\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 36.82it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9830\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 41.75it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.7158\n",
            "Start of experience  4\n",
            "-- >> Start of training phase << --\n",
            "Override the dataloader.\n",
            "100%|██████████| 127/127 [00:05<00:00, 22.94it/s]\n",
            "Epoch 0 ended.\n",
            "Buffer update.\n",
            "-- >> End of training phase << --\n",
            "Training completed\n",
            "Computing accuracy on the whole test set\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-04bf1c5bdbc6>:34: DeprecationWarning: Call to deprecated function update (removal in version 0.7: switch to pre_adapt and post_adapt)\n",
            "  self.storage_policy.update(strategy, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 40.62it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.7003\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 35.93it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.8249\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 21/21 [00:00<00:00, 37.54it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.7026\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 20/20 [00:00<00:00, 33.43it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.9623\n",
            "-- Starting eval on experience 4 (Task 0) from test stream --\n",
            "100%|██████████| 22/22 [00:00<00:00, 25.94it/s]\n",
            "> Eval on experience 4 (Task 0) from test stream ended.\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp004 = 0.9846\n",
            "-- >> End of eval phase << --\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.8362\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3F-4u7r0R05n"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}